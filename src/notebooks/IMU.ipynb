{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbrmsyoWm-1W"
      },
      "outputs": [],
      "source": [
        "import zipfile, os, gdown, math, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import gdown  # Required for Google Drive downloads\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from numpy.random import randn, rand\n",
        "\n",
        "# tidy default plotting\n",
        "plt.rcParams.update({\"figure.figsize\": (8,4), \"axes.grid\": True})\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('content/drive')\n",
        "\n",
        "'./thesis'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data loading"
      ],
      "metadata": {
        "id": "rz50bhwmSlnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DRIVE_FILES = {\n",
        "    \"imu_zip\"      : \"1-C_5HG-T6C9ZLBQktCDFiQoGmWbptQl6\",\n",
        "    \"ground_truth\" : \"1fMYkMq0EzDOmWj6SrBUwgABkq5NW14Xn\",\n",
        "    \"noise_zip\"    : \"1GvfgNiHE2pFaYkQ9ZiFJc0XNAzYviCU1\"\n",
        "}\n",
        "\n",
        "DATA_DIR = \"data\"                      # all files land here\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "def gdrive_download(file_id: str, dest: str) -> str:\n",
        "    if not os.path.exists(dest):\n",
        "        print(f\"⬇️  Downloading {os.path.basename(dest)} …\")\n",
        "        gdown.download(id=file_id, output=dest, quiet=False)\n",
        "    return dest\n",
        "\n",
        "imu_zip_path   = gdrive_download(DRIVE_FILES[\"imu_zip\"],      f\"{DATA_DIR}/imu.zip\")\n",
        "gt_csv_path    = gdrive_download(DRIVE_FILES[\"ground_truth\"], f\"{DATA_DIR}/ground_truth.csv\")\n",
        "noise_zip_path = gdrive_download(DRIVE_FILES[\"noise_zip\"],    f\"{DATA_DIR}/noise.zip\")\n",
        "\n",
        "with zipfile.ZipFile(imu_zip_path) as z:   z.extractall(f\"{DATA_DIR}/imu\")\n",
        "with zipfile.ZipFile(noise_zip_path) as z: z.extractall(f\"{DATA_DIR}/noise\")\n",
        "\n",
        "ACC_FILE = f\"{DATA_DIR}/imu/Accelerometer.csv\"\n",
        "GYR_FILE = f\"{DATA_DIR}/imu/Gyroscope.csv\"\n",
        "NOISE_ACC_FILE = f\"{DATA_DIR}/noise/Accelerometer.csv\"\n",
        "NOISE_GYR_FILE = f\"{DATA_DIR}/noise/Gyroscope.csv\"\n",
        "\n",
        "for f in [ACC_FILE, GYR_FILE, NOISE_ACC_FILE, NOISE_GYR_FILE]:\n",
        "    assert os.path.isfile(f), f\"Expected file {f} missing!\"\n",
        "print(\"✓ Files extracted\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VQem2lQPsCN",
        "outputId": "af30c6d6-8821-4de6-af44-975e261ce80e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️  Downloading imu.zip …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-C_5HG-T6C9ZLBQktCDFiQoGmWbptQl6\n",
            "To: /content/data/imu.zip\n",
            "100%|██████████| 351k/351k [00:00<00:00, 8.07MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️  Downloading ground_truth.csv …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1h9y_aboTQ1gTJs31esyVed1zWxhb7Ruy\n",
            "To: /content/data/ground_truth.csv\n",
            "100%|██████████| 29.7k/29.7k [00:00<00:00, 31.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⬇️  Downloading noise.zip …\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1GvfgNiHE2pFaYkQ9ZiFJc0XNAzYviCU1\n",
            "To: /content/data/noise.zip\n",
            "100%|██████████| 168k/168k [00:00<00:00, 4.06MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Files extracted\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMU"
      ],
      "metadata": {
        "id": "ynHWC3itShT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_rename(path, prefix):\n",
        "    df = pd.read_csv(path)\n",
        "    # keep original order z–y–x so head() matches your printout\n",
        "    if {\"x\",\"y\",\"z\"}.issubset(df.columns):\n",
        "        df = df[[\"time\",\"seconds_elapsed\",\"z\",\"y\",\"x\"]]   # reorder\n",
        "    df = df.rename(columns={\"x\":f\"{prefix}_x\",\n",
        "                            \"y\":f\"{prefix}_y\",\n",
        "                            \"z\":f\"{prefix}_z\"})\n",
        "    return df\n",
        "\n",
        "acc_raw = read_and_rename(ACC_FILE, \"Acc\")\n",
        "gyr_raw = read_and_rename(GYR_FILE, \"Gyro\")\n",
        "\n",
        "print(\"Accelerometer Data:\")\n",
        "print(acc_raw.head(), \"\\n\")\n",
        "print(\"Gyroscope Data:\")\n",
        "print(gyr_raw.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKNNCkhFPwGQ",
        "outputId": "53d432a3-a074-4d4f-bea9-1cbe0baeb2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accelerometer Data:\n",
            "                  time  seconds_elapsed     Acc_z     Acc_y     Acc_x\n",
            "0  1746650740041851600         0.022852 -0.053982 -0.010348  0.040906\n",
            "1  1746650740051817700         0.032818 -0.073131 -0.003087  0.017670\n",
            "2  1746650740061782500         0.042782 -0.059809 -0.009220  0.015778\n",
            "3  1746650740071748600         0.052749 -0.085699  0.003128  0.021464\n",
            "4  1746650740081714700         0.062715 -0.068490  0.004616 -0.001712 \n",
            "\n",
            "Gyroscope Data:\n",
            "                  time  seconds_elapsed    Gyro_z    Gyro_y    Gyro_x\n",
            "0  1746650740041851600         0.022852  0.000327 -0.003186  0.001806\n",
            "1  1746650740051817700         0.032818  0.002338 -0.003803 -0.003158\n",
            "2  1746650740061782500         0.042782 -0.001544 -0.001809 -0.000190\n",
            "3  1746650740071748600         0.052749 -0.000979 -0.003310 -0.002376\n",
            "4  1746650740081714700         0.062715  0.000285 -0.003655 -0.000411\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise"
      ],
      "metadata": {
        "id": "o4xSh2KGScdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc_noise = read_and_rename(NOISE_ACC_FILE, \"Acc\")\n",
        "gyr_noise = read_and_rename(NOISE_GYR_FILE, \"Gyro\")\n",
        "\n",
        "for df in (acc_noise, gyr_noise):\n",
        "    df.drop(columns=[\"seconds_elapsed\",\"time\"], inplace=True, errors=\"ignore\")"
      ],
      "metadata": {
        "id": "7Mgj171iQAy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ground truth"
      ],
      "metadata": {
        "id": "V2-Ji6AuSd09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gt = pd.read_csv(gt_csv_path)"
      ],
      "metadata": {
        "id": "nHv0NDFqQEuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "match time step"
      ],
      "metadata": {
        "id": "tpjIuMI1Iv6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = acc_raw\n",
        "gyr = gyr_raw\n",
        "tracker = gt\n",
        "\n",
        "tracker['t'] -= tracker['t'].iloc[0]\n",
        "acc['t']      = acc['seconds_elapsed']  - acc['seconds_elapsed'].iloc[0]\n",
        "gyr['t']      = gyr['seconds_elapsed']  - gyr['seconds_elapsed'].iloc[0]\n",
        "\n",
        "# b) use the *tracker* time-stamps as the reference grid\n",
        "tracker     = tracker.set_index('t')\n",
        "acc         = acc.set_index('t')\n",
        "gyr         = gyr.set_index('t')\n",
        "t_ref       = tracker.index            # ~33 ms spacing (30 Hz)\n",
        "\n",
        "# --- 3.  Interpolate phone sensors onto that grid -----------------------------\n",
        "# keep only the actual sensor columns and rename in a single go\n",
        "acc_interp = (\n",
        "    acc[['x', 'y', 'z']]\n",
        "    .reindex(t_ref)\n",
        "    .interpolate('linear')\n",
        "    .rename(columns=lambda c: f'acc_{c}')\n",
        ")\n",
        "gyr_interp = (\n",
        "    gyr[['x', 'y', 'z']]\n",
        "    .reindex(t_ref)\n",
        "    .interpolate('linear')\n",
        "    .rename(columns=lambda c: f'gyr_{c}')\n",
        ")\n",
        "\n",
        "# --- 4.  Merge everything ------------------------------------------------------\n",
        "aligned = pd.concat([tracker, acc_interp, gyr_interp], axis=1).dropna()\n",
        "\n",
        "# optional: save for KalmanNet / PyTorch dataloader\n",
        "aligned.to_csv('/content/aligned_kalmannet_input.csv', index=False)\n",
        "\n",
        "print('Aligned shape:', aligned.shape)\n",
        "aligned.head()\n",
        "print(aligned.columns.tolist())\n",
        "print(aligned.describe().T[['min','max','mean']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ee1nkI_gI2P5",
        "outputId": "6bd0ff11-62c2-4950-a156-178b540867e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['x', 'y', 'z'], dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-063a25e8feb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# keep only the actual sensor columns and rename in a single go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m acc_interp = (\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['x', 'y', 'z'], dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dt, matrix A and C"
      ],
      "metadata": {
        "id": "byuwyY6-S3OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = np.diff(acc_raw[\"seconds_elapsed\"].values).mean()\n",
        "I3, O3 = np.eye(3), np.zeros((3,3))\n",
        "\n",
        "A = np.block([[I3,         dt*I3, 0.5*(dt**2)*I3],\n",
        "              [O3,             I3,          dt*I3],\n",
        "              [O3,             O3,              I3]])\n",
        "\n",
        "C = np.hstack([O3, O3, I3])\n",
        "\n",
        "print(\"Δt =\", dt, \"\\n\")\n",
        "print(\"State-Transition Matrix  A:\\n\", A, \"\\n\")\n",
        "print(\"Observation Matrix  C:\\n\", C)"
      ],
      "metadata": {
        "id": "Amoqp4dsS6qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "noise covariance Q and R"
      ],
      "metadata": {
        "id": "Lkhv13-gTDHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sigma_acc, sigma_meas = 0.1, 0.05\n",
        "Q = sigma_acc**2 * np.block([\n",
        "    [0.25*dt**4*I3, 0.5*dt**3*I3, 0.5*dt**2*I3],\n",
        "    [0.5*dt**3*I3,     dt**2*I3,      dt*I3  ],\n",
        "    [0.5*dt**2*I3,        dt*I3,        I3    ]\n",
        "])\n",
        "R  = (sigma_meas**2)*I3\n",
        "x0 = np.zeros((9,1));   P0 = np.eye(9)"
      ],
      "metadata": {
        "id": "JJHbiBfoTHfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "orangize the data"
      ],
      "metadata": {
        "id": "dOZVbmBS0POZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA = {\n",
        "    \"acc_raw\"   : acc_raw,\n",
        "    \"gyr_raw\"   : gyr_raw,\n",
        "    \"acc_noise\" : acc_noise,\n",
        "    \"gyr_noise\" : gyr_noise,\n",
        "    \"truth\"     : gt,\n",
        "    \"dt\"        : dt,\n",
        "    \"A\"         : A,\n",
        "    \"C\"         : C,\n",
        "    \"Q\"         : Q,\n",
        "    \"R\"         : R,\n",
        "    \"x0\"        : x0,\n",
        "    \"P0\"        : P0\n",
        "}"
      ],
      "metadata": {
        "id": "BA1gHfBZTTcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low-Pass Filter"
      ],
      "metadata": {
        "id": "nhRAe4AzT3Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return filtfilt(b, a, data, axis=0)\n",
        "\n",
        "if 'dt' not in DATA or 'acc_raw' not in DATA:\n",
        "    raise RuntimeError(\"Run the file-loading cell first so DATA is defined.\")\n",
        "\n",
        "cutoff_hz = 5.0\n",
        "fs        = 1.0 / DATA['dt']\n",
        "\n",
        "acc_lpf = DATA['acc_raw'].copy()\n",
        "acc_lpf[['Acc_x','Acc_y','Acc_z']] = butter_lowpass_filter(\n",
        "        acc_lpf[['Acc_x','Acc_y','Acc_z']].values,\n",
        "        cutoff=cutoff_hz, fs=fs, order=4)\n",
        "\n",
        "DATA['acc_lpf'] = acc_lpf            # make it available downstream"
      ],
      "metadata": {
        "id": "jt5sp4MaT0kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Process & measurement models"
      ],
      "metadata": {
        "id": "tV-9jNeQbFh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DATA['dt']\n",
        "def process_model(X):\n",
        "    pos = X[:,0:3] + X[:,3:6]*dt + 0.5*X[:,6:9]*(dt**2)\n",
        "    vel = X[:,3:6] + X[:,6:9]*dt\n",
        "    acc = X[:,6:9]\n",
        "    return np.hstack([pos, vel, acc])\n",
        "\n",
        "def measurement_model(X):\n",
        "    return X[:,6:9]          # accelerometer gives us acceleration"
      ],
      "metadata": {
        "id": "xRS_YNvrbC7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Particle Filter"
      ],
      "metadata": {
        "id": "47A8Rx0lT_xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def particle_filter(acc_meas, Np=20):\n",
        "    T = len(acc_meas)\n",
        "    particles = np.tile(DATA['x0'].ravel(), (Np,1))\n",
        "    weights   = np.full(Np, 1.0/Np)\n",
        "    est_path  = np.zeros((T,3))\n",
        "\n",
        "    for k in range(T):\n",
        "        # 1. Prediction\n",
        "        particles = process_model(particles)\n",
        "        particles += np.random.multivariate_normal(\n",
        "                        mean=np.zeros(9), cov=DATA['Q'], size=Np)\n",
        "\n",
        "        # 2. Weight update\n",
        "        diffs      = acc_meas[k] - measurement_model(particles)\n",
        "        mahal2     = np.sum(diffs @ np.linalg.inv(DATA['R']) * diffs, axis=1)\n",
        "        weights   *= np.exp(-0.5*mahal2)\n",
        "        weights   += 1e-300\n",
        "        weights   /= weights.sum()\n",
        "\n",
        "        # 3. Systematic resample\n",
        "        cdf = np.cumsum(weights)\n",
        "        u0  = np.random.uniform(0, 1.0/Np)\n",
        "        idx = np.searchsorted(cdf, u0 + np.arange(Np)/Np)\n",
        "        particles = particles[idx]\n",
        "        weights.fill(1.0/Np)\n",
        "\n",
        "        est_path[k] = particles[:,0:3].mean(axis=0)\n",
        "\n",
        "    return est_path"
      ],
      "metadata": {
        "id": "iMqwfYABaHPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run and plot - PF"
      ],
      "metadata": {
        "id": "HJ3fZiZgbMXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ── 1. RUN THE FILTER ────────────────────────────────────────────────────────\n",
        "acc_array = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values\n",
        "pf_path   = particle_filter(acc_array, Np=20)          # ← adjust Np as desired\n",
        "DATA['pf_path'] = pf_path\n",
        "\n",
        "# ── 2. PLOT 2-D PATH  (tracker vs PF) ────────────────────────────────────────\n",
        "gt_xy = DATA['truth'][['x','y']].values\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(gt_xy[:,0], gt_xy[:,1], label='Tracker ground-truth', lw=2)\n",
        "plt.plot(pf_path[:,0], pf_path[:,1], label='Particle-filter estimate', alpha=0.8)\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]')\n",
        "plt.title('2-D path — Particle Filter vs Tracker')\n",
        "plt.axis('equal'); plt.legend(); plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ── 3. DERIVE ACCEL FROM PF POSITIONS  &  COMPARE TO REAL ACCEL ──────────────\n",
        "dt      = DATA['dt']\n",
        "vel_pf  = np.gradient(pf_path, dt, axis=0)\n",
        "acc_pf  = np.gradient(vel_pf, dt, axis=0)          # Âx, Ây, Âz\n",
        "acc_pf  = acc_pf[1:-1]                             # align lengths\n",
        "acc_real = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values[1:-1]\n",
        "t_steps  = np.arange(len(acc_pf))\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(9,6), sharex=True)\n",
        "\n",
        "axs[0].plot(t_steps, acc_real[:,0], label='Acc_x real')\n",
        "axs[0].plot(t_steps, acc_pf[:,0],  label='Acc_x derived', alpha=0.75)\n",
        "axs[0].set_ylabel('Acc_x  [m/s²]'); axs[0].legend(); axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(t_steps, acc_real[:,1], label='Acc_y real')\n",
        "axs[1].plot(t_steps, acc_pf[:,1],  label='Acc_y derived', alpha=0.75)\n",
        "axs[1].set_ylabel('Acc_y  [m/s²]'); axs[1].set_xlabel('Time step')\n",
        "axs[1].legend(); axs[1].grid(True)\n",
        "\n",
        "fig.suptitle('Comparison of Acceleration: Derived from Position vs Real Accelerometer')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "unOHpQgLbOBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klaman Filter"
      ],
      "metadata": {
        "id": "lgonG3chdJ07"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kalman_filter(acc_meas, A, C, Q, R, x0, P0):\n",
        "    \"\"\"\n",
        "    Linear Kalman filter for the 9-state [pos vel acc] model.\n",
        "    acc_meas : (T,3)   low-pass-filtered accelerometer samples\n",
        "    returns   : (T,9)  state history  [x y z  vx vy vz  ax ay az]\n",
        "    \"\"\"\n",
        "    T  = len(acc_meas)\n",
        "    nX = x0.shape[0]\n",
        "    x  = x0.copy()          # (9,1)\n",
        "    P  = P0.copy()          # (9,9)\n",
        "    xs = np.zeros((T, nX))  # store\n",
        "\n",
        "    for k in range(T):\n",
        "        # ─ Prediction\n",
        "        x = A @ x\n",
        "        P = A @ P @ A.T + Q\n",
        "\n",
        "        # ─ Update\n",
        "        z   = acc_meas[k].reshape(3,1)\n",
        "        y   = z - C @ x\n",
        "        S   = C @ P @ C.T + R\n",
        "        K   = P @ C.T @ np.linalg.inv(S)\n",
        "        x   = x + K @ y\n",
        "        P   = (np.eye(nX) - K @ C) @ P\n",
        "\n",
        "        xs[k] = x.ravel()\n",
        "\n",
        "    return xs\n",
        "\n",
        "# ── 2. RUN THE FILTER ───────────────────────────────────────────────────────\n",
        "acc_meas = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values\n",
        "kf_states = kalman_filter(acc_meas,\n",
        "                          DATA['A'], DATA['C'],\n",
        "                          DATA['Q'], DATA['R'],\n",
        "                          DATA['x0'], DATA['P0'])\n",
        "\n",
        "kf_path = kf_states[:, 0:3]          # positions are first 3 components\n",
        "DATA['kf_path'] = kf_path            # stash for later comparisons\n",
        "\n",
        "# ── 3. PLOT 2-D PATH  (ground-truth vs KF, optional PF) ─────────────────────\n",
        "gt_xy = DATA['truth'][['x', 'y']].values\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(gt_xy[:,0], gt_xy[:,1], label='Tracker ground-truth', lw=2)\n",
        "plt.plot(kf_path[:,0], kf_path[:,1], label='Kalman-filter estimate', alpha=0.85)\n",
        "\n",
        "# optional: overlay PF if it exists\n",
        "if 'pf_path' in DATA:\n",
        "    plt.plot(DATA['pf_path'][:,0], DATA['pf_path'][:,1],\n",
        "             label='Particle-filter estimate', alpha=0.6)\n",
        "\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]')\n",
        "plt.title('2-D path — Kalman Filter (and PF) vs Tracker')\n",
        "plt.axis('equal'); plt.legend(); plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HRspDS-IfUlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KlamanNet - model"
      ],
      "metadata": {
        "id": "ydPtYUl0dMwl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using\", device)\n",
        "\n",
        "class KNet(nn.Module):\n",
        "    def __init__(self, n_x=9, n_y=3, hidden=528, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.n_x, self.n_y = n_x, n_y\n",
        "        self.gru  = nn.GRU(input_size=n_y+n_x, hidden_size=hidden,\n",
        "                           num_layers=num_layers, batch_first=True)\n",
        "        self.fc   = nn.Sequential(nn.Linear(hidden, n_x*n_y))\n",
        "        # register constant matrices so they move with .to(device)\n",
        "        self.register_buffer(\"A\", torch.from_numpy(DATA['A']).float())\n",
        "        self.register_buffer(\"C\", torch.from_numpy(DATA['C']).float())\n",
        "\n",
        "    def forward(self, y_seq):\n",
        "        \"\"\"\n",
        "        y_seq : (B,T,n_y)   – mini-batch of measurement sequences\n",
        "        returns: (B,T,n_x)  – KalmanNet state estimates\n",
        "        \"\"\"\n",
        "        B, T, _ = y_seq.shape\n",
        "        h = torch.zeros(self.gru.num_layers, B, self.gru.hidden_size,\n",
        "                        device=y_seq.device)\n",
        "        # pre-allocate\n",
        "        x_hat = torch.zeros(B, T, self.n_x, device=y_seq.device)\n",
        "\n",
        "        # initialise with zeros\n",
        "        x_prev = torch.zeros(B, self.n_x, device=y_seq.device)\n",
        "\n",
        "        for t in range(T):\n",
        "            # Predict step (classic model) ---------------------------------\n",
        "            x_pred = (self.A @ x_prev.unsqueeze(-1)).squeeze(-1)  # (B,n_x)\n",
        "            y_pred = (self.C @ x_pred.unsqueeze(-1)).squeeze(-1)  # (B,n_y)\n",
        "            innov  = y_seq[:,t] - y_pred                          # (B,n_y)\n",
        "\n",
        "            gru_in = torch.cat([innov, x_pred], dim=-1)           # (B,n_y+n_x)\n",
        "            gru_out, h = self.gru(gru_in.unsqueeze(1), h)         # (B,1,H)\n",
        "            K_t     = self.fc(gru_out.squeeze(1))                 # (B,n_x*n_y)\n",
        "            K_t     = K_t.view(B, self.n_x, self.n_y)             # Kalman gain\n",
        "\n",
        "            # Correct step -----------------------------------------------\n",
        "            x_upd  = x_pred.unsqueeze(-1) + K_t @ innov.unsqueeze(-1)\n",
        "            x_prev = x_upd.squeeze(-1)\n",
        "            x_hat[:,t] = x_prev\n",
        "\n",
        "        return x_hat"
      ],
      "metadata": {
        "id": "VAsWY00ZiK3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KN - training"
      ],
      "metadata": {
        "id": "9h8iJAMIjBPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len, stride = 50, 5\n",
        "dt              = DATA['dt']\n",
        "\n",
        "# ---- ground-truth position ---------------------------------------------------\n",
        "truth_df = DATA['truth'].copy()\n",
        "if 'z' not in truth_df.columns:            # add zero-height if missing\n",
        "    truth_df['z'] = 0.0\n",
        "gt_pos = torch.tensor(truth_df[['x','y','z']].values,\n",
        "                      dtype=torch.float32)\n",
        "\n",
        "# ---- accelerometer (low-pass) ------------------------------------------------\n",
        "acc_lpf = torch.tensor(\n",
        "    DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values,\n",
        "    dtype=torch.float32)\n",
        "\n",
        "# ---- length-alignment  (trim both to min length) ----------------------------\n",
        "T = min(len(acc_lpf), len(gt_pos))\n",
        "acc_lpf = acc_lpf[:T]\n",
        "gt_pos  = gt_pos[:T]\n",
        "\n",
        "# ---- differentiate to get vel & acc -----------------------------------------\n",
        "vel_gt = torch.diff(gt_pos, dim=0, prepend=gt_pos[0:1]) / dt\n",
        "acc_gt = torch.diff(vel_gt, dim=0, prepend=vel_gt[0:1]) / dt\n",
        "state_gt = torch.cat([gt_pos, vel_gt, acc_gt], dim=1)      # (T,9)\n",
        "\n",
        "# ---- window into mini-sequences ---------------------------------------------\n",
        "def windowed(x, L, s):\n",
        "    idx = torch.arange(0, x.shape[0]-L+1, s)\n",
        "    return torch.stack([x[i:i+L] for i in idx])\n",
        "\n",
        "Y = windowed(acc_lpf,  seq_len, stride)   # (N,L,3)  measurements\n",
        "X = windowed(state_gt, seq_len, stride)   # (N,L,9)  targets\n",
        "\n",
        "split = int(0.8 * len(Y))\n",
        "Y_train, Y_val = Y[:split], Y[split:]\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "\n",
        "\n",
        "# ---- training loop---------------------------------------\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_knet(model, Ytr, Xtr, Yval, Xval, epochs=30, lr=1e-3):\n",
        "    model.to(device)\n",
        "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        pred = model(Ytr.to(device))\n",
        "        loss = loss_fn(pred, Xtr.to(device))\n",
        "        loss.backward(); opt.step()\n",
        "\n",
        "        # ---- validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val = loss_fn(model(Yval.to(device)), Xval.to(device)).item()\n",
        "        if ep % 5 == 0 or ep == 1:\n",
        "            print(f\"epoch {ep:3d}  train={loss.item():.4e}  val={val:.4e}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "knet = train_knet(KNet(), Y_train, X_train, Y_val, X_val,\n",
        "                  epochs=40, lr=1e-3)"
      ],
      "metadata": {
        "id": "ZO8XPbcPjGeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KN- FULL-SEQUENCE INFERENCE  +  PLOTS"
      ],
      "metadata": {
        "id": "XJURHGaElY8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knet.eval()\n",
        "with torch.no_grad():\n",
        "    knet_states = knet(acc_lpf.unsqueeze(0).to(device)).cpu().squeeze(0).numpy()\n",
        "knet_path = knet_states[:,0:3]\n",
        "DATA['knet_path'] = knet_path\n",
        "DATA['acc_lpf_trimmed'] = acc_lpf        # keep the synced version\n",
        "\n",
        "# ---- PATH PLOT ----------------------------------------------------------------\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(DATA['truth']['x'], DATA['truth']['y'], label='Tracker GT', lw=2)\n",
        "plt.plot(DATA['kf_path'][:,0],  DATA['kf_path'][:,1],  label='Kalman Filter')\n",
        "plt.plot(knet_path[:,0],        knet_path[:,1],        label='KalmanNet', alpha=0.85)\n",
        "if 'pf_path' in DATA:\n",
        "    plt.plot(DATA['pf_path'][:,0], DATA['pf_path'][:,1], label='Particle Filter', alpha=0.6)\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]'); plt.axis('equal')\n",
        "plt.title('2-D path — Tracker vs KF vs KalmanNet')\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---- ACCELERATION COMPARISON (derived vs real) --------------------------------\n",
        "dt     = DATA['dt']\n",
        "vel_kn = np.gradient(knet_path, dt, axis=0)\n",
        "acc_kn = np.gradient(vel_kn, dt, axis=0)[1:-1]\n",
        "acc_rl = DATA['acc_lpf_trimmed'][1:-1]        # synced real accel\n",
        "ts     = np.arange(len(acc_kn))\n",
        "\n",
        "fig,axs = plt.subplots(2,1,figsize=(9,6),sharex=True)\n",
        "axs[0].plot(ts, acc_rl[:,0], label='Acc_x real')\n",
        "axs[0].plot(ts, acc_kn[:,0], label='Acc_x KalmanNet', alpha=0.7)\n",
        "axs[0].set_ylabel('Acc_x'); axs[0].grid(); axs[0].legend()\n",
        "\n",
        "axs[1].plot(ts, acc_rl[:,1], label='Acc_y real')\n",
        "axs[1].plot(ts, acc_kn[:,1], label='Acc_y KalmanNet', alpha=0.7)\n",
        "axs[1].set_ylabel('Acc_y'); axs[1].set_xlabel('Time step'); axs[1].grid(); axs[1].legend()\n",
        "\n",
        "fig.suptitle('Acceleration: KalmanNet-derived vs Real Accelerometer')\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "CAkfTi66lOWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparison tables and graph"
      ],
      "metadata": {
        "id": "vW_ma5sPdPD1"
      }
    }
  ]
}