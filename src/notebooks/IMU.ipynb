{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZbrmsyoWm-1W"
      },
      "outputs": [],
      "source": [
        "import zipfile, os, math, random, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from numpy.random import randn, rand\n",
        "\n",
        "# tidy default plotting\n",
        "plt.rcParams.update({\"figure.figsize\": (8,4), \"axes.grid\": True})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz50bhwmSlnA"
      },
      "source": [
        "Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VQem2lQPsCN",
        "outputId": "af30c6d6-8821-4de6-af44-975e261ce80e"
      },
      "outputs": [],
      "source": [
        "FILES = {\n",
        "    \"acc\": \"data/Accelerometer.csv\",\n",
        "    \"gyr\": \"data/Gyroscope.csv\",\n",
        "    \"trk\": \"data/Tracker_aligned.csv\"\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynHWC3itShT6"
      },
      "source": [
        "IMU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKNNCkhFPwGQ",
        "outputId": "53d432a3-a074-4d4f-bea9-1cbe0baeb2e3"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     64\u001b[0m     trk, gyr, acc \u001b[38;5;241m=\u001b[39m FILES\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracker   : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrk\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGyroscope : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgyr\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccelerom.: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "# data_io.py  ── v3  (keys = \"acc\", \"gyr\", \"trk\")\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# File locations ─ adjust the DATA_DIR if your CSVs live elsewhere\n",
        "\n",
        "FILES = {\n",
        "    \"acc\": \"Accelerometer.csv\",\n",
        "    \"gyr\": \"Gyroscope.csv\",\n",
        "    \"trk\": \"Tracker_aligned.csv\",\n",
        "}\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def _read_csv(path: Path) -> pd.DataFrame:\n",
        "    \"\"\"Load one CSV, drop the raw ‘time’ column, index on `seconds_elapsed`.\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    if \"time\" in df.columns:              # strip useless time-of-day ticks\n",
        "        df = df.drop(columns=[\"time\"])\n",
        "\n",
        "    if \"seconds_elapsed\" not in df.columns:\n",
        "        raise KeyError(f\"`seconds_elapsed` missing in {path.name}\")\n",
        "\n",
        "    return (\n",
        "        df.set_index(\"seconds_elapsed\")   # float seconds from log start\n",
        "          .sort_index()\n",
        "    )\n",
        "\n",
        "\n",
        "def load_raw_frames() -> dict[str, pd.DataFrame]:\n",
        "    \"\"\"Return dict of raw (time-indexed) DataFrames – keys = acc, gyr, trk.\"\"\"\n",
        "    frames = {k: _read_csv(p) for k, p in FILES.items()}\n",
        "    assert all(len(f) for f in frames.values()), \"one of the CSVs is empty\"\n",
        "    return frames\n",
        "\n",
        "\n",
        "def load_synced_arrays() -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Return (trk, gyr, acc) as perfectly time-aligned NumPy arrays (float32).\n",
        "\n",
        "    • Forward-fills tiny gaps  \n",
        "    • Uses the intersection of all time stamps to guarantee consistency\n",
        "    \"\"\"\n",
        "    frames = load_raw_frames()\n",
        "    frames = {k: f.ffill() for k, f in frames.items()}\n",
        "\n",
        "    common_index = frames[\"trk\"].index\n",
        "    for f in frames.values():\n",
        "        common_index = common_index.intersection(f.index)\n",
        "\n",
        "    frames = {k: f.loc[common_index] for k, f in frames.items()}\n",
        "\n",
        "    trk_arr = frames[\"trk\"].to_numpy(dtype=np.float32)\n",
        "    gyr_arr = frames[\"gyr\"].to_numpy(dtype=np.float32)\n",
        "    acc_arr = frames[\"acc\"].to_numpy(dtype=np.float32)\n",
        "\n",
        "    return trk_arr, gyr_arr, acc_arr\n",
        "\n",
        "\n",
        "# quick smoke-test ─ run “python data_io.py” to see the shapes\n",
        "if __name__ == \"__main__\":\n",
        "    trk, gyr, acc = FILES\n",
        "    print(f\"Tracker   : {trk.shape}\")\n",
        "    print(f\"Gyroscope : {gyr.shape}\")\n",
        "    print(f\"Accelerom.: {acc.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4xSh2KGScdR"
      },
      "source": [
        "Noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Mgj171iQAy9"
      },
      "outputs": [],
      "source": [
        "acc_noise = read_and_rename(NOISE_ACC_FILE, \"Acc\")\n",
        "gyr_noise = read_and_rename(NOISE_GYR_FILE, \"Gyro\")\n",
        "\n",
        "for df in (acc_noise, gyr_noise):\n",
        "    df.drop(columns=[\"seconds_elapsed\",\"time\"], inplace=True, errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2-Ji6AuSd09"
      },
      "source": [
        "Ground truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHv0NDFqQEuN"
      },
      "outputs": [],
      "source": [
        "gt = pd.read_csv(gt_csv_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpjIuMI1Iv6b"
      },
      "source": [
        "match time step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ee1nkI_gI2P5",
        "outputId": "6bd0ff11-62c2-4950-a156-178b540867e1"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"None of [Index(['x', 'y', 'z'], dtype='object')] are in the [columns]\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-063a25e8feb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# keep only the actual sensor columns and rename in a single go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m acc_interp = (\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0macc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6247\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6248\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6249\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['x', 'y', 'z'], dtype='object')] are in the [columns]\""
          ]
        }
      ],
      "source": [
        "acc = acc_raw\n",
        "gyr = gyr_raw\n",
        "tracker = gt\n",
        "\n",
        "tracker['t'] -= tracker['t'].iloc[0]\n",
        "acc['t']      = acc['seconds_elapsed']  - acc['seconds_elapsed'].iloc[0]\n",
        "gyr['t']      = gyr['seconds_elapsed']  - gyr['seconds_elapsed'].iloc[0]\n",
        "\n",
        "# b) use the *tracker* time-stamps as the reference grid\n",
        "tracker     = tracker.set_index('t')\n",
        "acc         = acc.set_index('t')\n",
        "gyr         = gyr.set_index('t')\n",
        "t_ref       = tracker.index            # ~33 ms spacing (30 Hz)\n",
        "\n",
        "# --- 3.  Interpolate phone sensors onto that grid -----------------------------\n",
        "# keep only the actual sensor columns and rename in a single go\n",
        "acc_interp = (\n",
        "    acc[['x', 'y', 'z']]\n",
        "    .reindex(t_ref)\n",
        "    .interpolate('linear')\n",
        "    .rename(columns=lambda c: f'acc_{c}')\n",
        ")\n",
        "gyr_interp = (\n",
        "    gyr[['x', 'y', 'z']]\n",
        "    .reindex(t_ref)\n",
        "    .interpolate('linear')\n",
        "    .rename(columns=lambda c: f'gyr_{c}')\n",
        ")\n",
        "\n",
        "# --- 4.  Merge everything ------------------------------------------------------\n",
        "aligned = pd.concat([tracker, acc_interp, gyr_interp], axis=1).dropna()\n",
        "\n",
        "# optional: save for KalmanNet / PyTorch dataloader\n",
        "aligned.to_csv('/content/aligned_kalmannet_input.csv', index=False)\n",
        "\n",
        "print('Aligned shape:', aligned.shape)\n",
        "aligned.head()\n",
        "print(aligned.columns.tolist())\n",
        "print(aligned.describe().T[['min','max','mean']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byuwyY6-S3OH"
      },
      "source": [
        "dt, matrix A and C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Amoqp4dsS6qk"
      },
      "outputs": [],
      "source": [
        "dt = np.diff(acc_raw[\"seconds_elapsed\"].values).mean()\n",
        "I3, O3 = np.eye(3), np.zeros((3,3))\n",
        "\n",
        "A = np.block([[I3,         dt*I3, 0.5*(dt**2)*I3],\n",
        "              [O3,             I3,          dt*I3],\n",
        "              [O3,             O3,              I3]])\n",
        "\n",
        "C = np.hstack([O3, O3, I3])\n",
        "\n",
        "print(\"Δt =\", dt, \"\\n\")\n",
        "print(\"State-Transition Matrix  A:\\n\", A, \"\\n\")\n",
        "print(\"Observation Matrix  C:\\n\", C)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkhv13-gTDHJ"
      },
      "source": [
        "noise covariance Q and R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJHbiBfoTHfF"
      },
      "outputs": [],
      "source": [
        "sigma_acc, sigma_meas = 0.1, 0.05\n",
        "Q = sigma_acc**2 * np.block([\n",
        "    [0.25*dt**4*I3, 0.5*dt**3*I3, 0.5*dt**2*I3],\n",
        "    [0.5*dt**3*I3,     dt**2*I3,      dt*I3  ],\n",
        "    [0.5*dt**2*I3,        dt*I3,        I3    ]\n",
        "])\n",
        "R  = (sigma_meas**2)*I3\n",
        "x0 = np.zeros((9,1));   P0 = np.eye(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOZVbmBS0POZ"
      },
      "source": [
        "orangize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BA1gHfBZTTcF"
      },
      "outputs": [],
      "source": [
        "DATA = {\n",
        "    \"acc_raw\"   : acc_raw,\n",
        "    \"gyr_raw\"   : gyr_raw,\n",
        "    \"acc_noise\" : acc_noise,\n",
        "    \"gyr_noise\" : gyr_noise,\n",
        "    \"truth\"     : gt,\n",
        "    \"dt\"        : dt,\n",
        "    \"A\"         : A,\n",
        "    \"C\"         : C,\n",
        "    \"Q\"         : Q,\n",
        "    \"R\"         : R,\n",
        "    \"x0\"        : x0,\n",
        "    \"P0\"        : P0\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhRAe4AzT3Ea"
      },
      "source": [
        "Low-Pass Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt5sp4MaT0kQ"
      },
      "outputs": [],
      "source": [
        "from scipy.signal import butter, filtfilt\n",
        "\n",
        "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
        "    nyq = 0.5 * fs\n",
        "    normal_cutoff = cutoff / nyq\n",
        "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
        "    return filtfilt(b, a, data, axis=0)\n",
        "\n",
        "if 'dt' not in DATA or 'acc_raw' not in DATA:\n",
        "    raise RuntimeError(\"Run the file-loading cell first so DATA is defined.\")\n",
        "\n",
        "cutoff_hz = 5.0\n",
        "fs        = 1.0 / DATA['dt']\n",
        "\n",
        "acc_lpf = DATA['acc_raw'].copy()\n",
        "acc_lpf[['Acc_x','Acc_y','Acc_z']] = butter_lowpass_filter(\n",
        "        acc_lpf[['Acc_x','Acc_y','Acc_z']].values,\n",
        "        cutoff=cutoff_hz, fs=fs, order=4)\n",
        "\n",
        "DATA['acc_lpf'] = acc_lpf            # make it available downstream"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tV-9jNeQbFh0"
      },
      "source": [
        "Process & measurement models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRS_YNvrbC7f"
      },
      "outputs": [],
      "source": [
        "dt = DATA['dt']\n",
        "def process_model(X):\n",
        "    pos = X[:,0:3] + X[:,3:6]*dt + 0.5*X[:,6:9]*(dt**2)\n",
        "    vel = X[:,3:6] + X[:,6:9]*dt\n",
        "    acc = X[:,6:9]\n",
        "    return np.hstack([pos, vel, acc])\n",
        "\n",
        "def measurement_model(X):\n",
        "    return X[:,6:9]          # accelerometer gives us acceleration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47A8Rx0lT_xk"
      },
      "source": [
        "Particle Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iMqwfYABaHPq"
      },
      "outputs": [],
      "source": [
        "def particle_filter(acc_meas, Np=20):\n",
        "    T = len(acc_meas)\n",
        "    particles = np.tile(DATA['x0'].ravel(), (Np,1))\n",
        "    weights   = np.full(Np, 1.0/Np)\n",
        "    est_path  = np.zeros((T,3))\n",
        "\n",
        "    for k in range(T):\n",
        "        # 1. Prediction\n",
        "        particles = process_model(particles)\n",
        "        particles += np.random.multivariate_normal(\n",
        "                        mean=np.zeros(9), cov=DATA['Q'], size=Np)\n",
        "\n",
        "        # 2. Weight update\n",
        "        diffs      = acc_meas[k] - measurement_model(particles)\n",
        "        mahal2     = np.sum(diffs @ np.linalg.inv(DATA['R']) * diffs, axis=1)\n",
        "        weights   *= np.exp(-0.5*mahal2)\n",
        "        weights   += 1e-300\n",
        "        weights   /= weights.sum()\n",
        "\n",
        "        # 3. Systematic resample\n",
        "        cdf = np.cumsum(weights)\n",
        "        u0  = np.random.uniform(0, 1.0/Np)\n",
        "        idx = np.searchsorted(cdf, u0 + np.arange(Np)/Np)\n",
        "        particles = particles[idx]\n",
        "        weights.fill(1.0/Np)\n",
        "\n",
        "        est_path[k] = particles[:,0:3].mean(axis=0)\n",
        "\n",
        "    return est_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3fZiZgbMXb"
      },
      "source": [
        "Run and plot - PF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unOHpQgLbOBc"
      },
      "outputs": [],
      "source": [
        "# ── 1. RUN THE FILTER ────────────────────────────────────────────────────────\n",
        "acc_array = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values\n",
        "pf_path   = particle_filter(acc_array, Np=20)          # ← adjust Np as desired\n",
        "DATA['pf_path'] = pf_path\n",
        "\n",
        "# ── 2. PLOT 2-D PATH  (tracker vs PF) ────────────────────────────────────────\n",
        "gt_xy = DATA['truth'][['x','y']].values\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(gt_xy[:,0], gt_xy[:,1], label='Tracker ground-truth', lw=2)\n",
        "plt.plot(pf_path[:,0], pf_path[:,1], label='Particle-filter estimate', alpha=0.8)\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]')\n",
        "plt.title('2-D path — Particle Filter vs Tracker')\n",
        "plt.axis('equal'); plt.legend(); plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ── 3. DERIVE ACCEL FROM PF POSITIONS  &  COMPARE TO REAL ACCEL ──────────────\n",
        "dt      = DATA['dt']\n",
        "vel_pf  = np.gradient(pf_path, dt, axis=0)\n",
        "acc_pf  = np.gradient(vel_pf, dt, axis=0)          # Âx, Ây, Âz\n",
        "acc_pf  = acc_pf[1:-1]                             # align lengths\n",
        "acc_real = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values[1:-1]\n",
        "t_steps  = np.arange(len(acc_pf))\n",
        "\n",
        "fig, axs = plt.subplots(2, 1, figsize=(9,6), sharex=True)\n",
        "\n",
        "axs[0].plot(t_steps, acc_real[:,0], label='Acc_x real')\n",
        "axs[0].plot(t_steps, acc_pf[:,0],  label='Acc_x derived', alpha=0.75)\n",
        "axs[0].set_ylabel('Acc_x  [m/s²]'); axs[0].legend(); axs[0].grid(True)\n",
        "\n",
        "axs[1].plot(t_steps, acc_real[:,1], label='Acc_y real')\n",
        "axs[1].plot(t_steps, acc_pf[:,1],  label='Acc_y derived', alpha=0.75)\n",
        "axs[1].set_ylabel('Acc_y  [m/s²]'); axs[1].set_xlabel('Time step')\n",
        "axs[1].legend(); axs[1].grid(True)\n",
        "\n",
        "fig.suptitle('Comparison of Acceleration: Derived from Position vs Real Accelerometer')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgonG3chdJ07"
      },
      "source": [
        "Klaman Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRspDS-IfUlZ"
      },
      "outputs": [],
      "source": [
        "def kalman_filter(acc_meas, A, C, Q, R, x0, P0):\n",
        "    \"\"\"\n",
        "    Linear Kalman filter for the 9-state [pos vel acc] model.\n",
        "    acc_meas : (T,3)   low-pass-filtered accelerometer samples\n",
        "    returns   : (T,9)  state history  [x y z  vx vy vz  ax ay az]\n",
        "    \"\"\"\n",
        "    T  = len(acc_meas)\n",
        "    nX = x0.shape[0]\n",
        "    x  = x0.copy()          # (9,1)\n",
        "    P  = P0.copy()          # (9,9)\n",
        "    xs = np.zeros((T, nX))  # store\n",
        "\n",
        "    for k in range(T):\n",
        "        # ─ Prediction\n",
        "        x = A @ x\n",
        "        P = A @ P @ A.T + Q\n",
        "\n",
        "        # ─ Update\n",
        "        z   = acc_meas[k].reshape(3,1)\n",
        "        y   = z - C @ x\n",
        "        S   = C @ P @ C.T + R\n",
        "        K   = P @ C.T @ np.linalg.inv(S)\n",
        "        x   = x + K @ y\n",
        "        P   = (np.eye(nX) - K @ C) @ P\n",
        "\n",
        "        xs[k] = x.ravel()\n",
        "\n",
        "    return xs\n",
        "\n",
        "# ── 2. RUN THE FILTER ───────────────────────────────────────────────────────\n",
        "acc_meas = DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values\n",
        "kf_states = kalman_filter(acc_meas,\n",
        "                          DATA['A'], DATA['C'],\n",
        "                          DATA['Q'], DATA['R'],\n",
        "                          DATA['x0'], DATA['P0'])\n",
        "\n",
        "kf_path = kf_states[:, 0:3]          # positions are first 3 components\n",
        "DATA['kf_path'] = kf_path            # stash for later comparisons\n",
        "\n",
        "# ── 3. PLOT 2-D PATH  (ground-truth vs KF, optional PF) ─────────────────────\n",
        "gt_xy = DATA['truth'][['x', 'y']].values\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(gt_xy[:,0], gt_xy[:,1], label='Tracker ground-truth', lw=2)\n",
        "plt.plot(kf_path[:,0], kf_path[:,1], label='Kalman-filter estimate', alpha=0.85)\n",
        "\n",
        "# optional: overlay PF if it exists\n",
        "if 'pf_path' in DATA:\n",
        "    plt.plot(DATA['pf_path'][:,0], DATA['pf_path'][:,1],\n",
        "             label='Particle-filter estimate', alpha=0.6)\n",
        "\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]')\n",
        "plt.title('2-D path — Kalman Filter (and PF) vs Tracker')\n",
        "plt.axis('equal'); plt.legend(); plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydPtYUl0dMwl"
      },
      "source": [
        "KlamanNet - model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAsWY00ZiK3X"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using\", device)\n",
        "\n",
        "class KNet(nn.Module):\n",
        "    def __init__(self, n_x=9, n_y=3, hidden=528, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.n_x, self.n_y = n_x, n_y\n",
        "        self.gru  = nn.GRU(input_size=n_y+n_x, hidden_size=hidden,\n",
        "                           num_layers=num_layers, batch_first=True)\n",
        "        self.fc   = nn.Sequential(nn.Linear(hidden, n_x*n_y))\n",
        "        # register constant matrices so they move with .to(device)\n",
        "        self.register_buffer(\"A\", torch.from_numpy(DATA['A']).float())\n",
        "        self.register_buffer(\"C\", torch.from_numpy(DATA['C']).float())\n",
        "\n",
        "    def forward(self, y_seq):\n",
        "        \"\"\"\n",
        "        y_seq : (B,T,n_y)   – mini-batch of measurement sequences\n",
        "        returns: (B,T,n_x)  – KalmanNet state estimates\n",
        "        \"\"\"\n",
        "        B, T, _ = y_seq.shape\n",
        "        h = torch.zeros(self.gru.num_layers, B, self.gru.hidden_size,\n",
        "                        device=y_seq.device)\n",
        "        # pre-allocate\n",
        "        x_hat = torch.zeros(B, T, self.n_x, device=y_seq.device)\n",
        "\n",
        "        # initialise with zeros\n",
        "        x_prev = torch.zeros(B, self.n_x, device=y_seq.device)\n",
        "\n",
        "        for t in range(T):\n",
        "            # Predict step (classic model) ---------------------------------\n",
        "            x_pred = (self.A @ x_prev.unsqueeze(-1)).squeeze(-1)  # (B,n_x)\n",
        "            y_pred = (self.C @ x_pred.unsqueeze(-1)).squeeze(-1)  # (B,n_y)\n",
        "            innov  = y_seq[:,t] - y_pred                          # (B,n_y)\n",
        "\n",
        "            gru_in = torch.cat([innov, x_pred], dim=-1)           # (B,n_y+n_x)\n",
        "            gru_out, h = self.gru(gru_in.unsqueeze(1), h)         # (B,1,H)\n",
        "            K_t     = self.fc(gru_out.squeeze(1))                 # (B,n_x*n_y)\n",
        "            K_t     = K_t.view(B, self.n_x, self.n_y)             # Kalman gain\n",
        "\n",
        "            # Correct step -----------------------------------------------\n",
        "            x_upd  = x_pred.unsqueeze(-1) + K_t @ innov.unsqueeze(-1)\n",
        "            x_prev = x_upd.squeeze(-1)\n",
        "            x_hat[:,t] = x_prev\n",
        "\n",
        "        return x_hat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h8iJAMIjBPK"
      },
      "source": [
        "KN - training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO8XPbcPjGeM"
      },
      "outputs": [],
      "source": [
        "seq_len, stride = 50, 5\n",
        "dt              = DATA['dt']\n",
        "\n",
        "# ---- ground-truth position ---------------------------------------------------\n",
        "truth_df = DATA['truth'].copy()\n",
        "if 'z' not in truth_df.columns:            # add zero-height if missing\n",
        "    truth_df['z'] = 0.0\n",
        "gt_pos = torch.tensor(truth_df[['x','y','z']].values,\n",
        "                      dtype=torch.float32)\n",
        "\n",
        "# ---- accelerometer (low-pass) ------------------------------------------------\n",
        "acc_lpf = torch.tensor(\n",
        "    DATA['acc_lpf'][['Acc_x','Acc_y','Acc_z']].values,\n",
        "    dtype=torch.float32)\n",
        "\n",
        "# ---- length-alignment  (trim both to min length) ----------------------------\n",
        "T = min(len(acc_lpf), len(gt_pos))\n",
        "acc_lpf = acc_lpf[:T]\n",
        "gt_pos  = gt_pos[:T]\n",
        "\n",
        "# ---- differentiate to get vel & acc -----------------------------------------\n",
        "vel_gt = torch.diff(gt_pos, dim=0, prepend=gt_pos[0:1]) / dt\n",
        "acc_gt = torch.diff(vel_gt, dim=0, prepend=vel_gt[0:1]) / dt\n",
        "state_gt = torch.cat([gt_pos, vel_gt, acc_gt], dim=1)      # (T,9)\n",
        "\n",
        "# ---- window into mini-sequences ---------------------------------------------\n",
        "def windowed(x, L, s):\n",
        "    idx = torch.arange(0, x.shape[0]-L+1, s)\n",
        "    return torch.stack([x[i:i+L] for i in idx])\n",
        "\n",
        "Y = windowed(acc_lpf,  seq_len, stride)   # (N,L,3)  measurements\n",
        "X = windowed(state_gt, seq_len, stride)   # (N,L,9)  targets\n",
        "\n",
        "split = int(0.8 * len(Y))\n",
        "Y_train, Y_val = Y[:split], Y[split:]\n",
        "X_train, X_val = X[:split], X[split:]\n",
        "\n",
        "\n",
        "# ---- training loop---------------------------------------\n",
        "import torch.optim as optim\n",
        "\n",
        "def train_knet(model, Ytr, Xtr, Yval, Xval, epochs=30, lr=1e-3):\n",
        "    model.to(device)\n",
        "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        pred = model(Ytr.to(device))\n",
        "        loss = loss_fn(pred, Xtr.to(device))\n",
        "        loss.backward(); opt.step()\n",
        "\n",
        "        # ---- validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val = loss_fn(model(Yval.to(device)), Xval.to(device)).item()\n",
        "        if ep % 5 == 0 or ep == 1:\n",
        "            print(f\"epoch {ep:3d}  train={loss.item():.4e}  val={val:.4e}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "knet = train_knet(KNet(), Y_train, X_train, Y_val, X_val,\n",
        "                  epochs=40, lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJURHGaElY8H"
      },
      "source": [
        "KN- FULL-SEQUENCE INFERENCE  +  PLOTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAkfTi66lOWO"
      },
      "outputs": [],
      "source": [
        "knet.eval()\n",
        "with torch.no_grad():\n",
        "    knet_states = knet(acc_lpf.unsqueeze(0).to(device)).cpu().squeeze(0).numpy()\n",
        "knet_path = knet_states[:,0:3]\n",
        "DATA['knet_path'] = knet_path\n",
        "DATA['acc_lpf_trimmed'] = acc_lpf        # keep the synced version\n",
        "\n",
        "# ---- PATH PLOT ----------------------------------------------------------------\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.plot(DATA['truth']['x'], DATA['truth']['y'], label='Tracker GT', lw=2)\n",
        "plt.plot(DATA['kf_path'][:,0],  DATA['kf_path'][:,1],  label='Kalman Filter')\n",
        "plt.plot(knet_path[:,0],        knet_path[:,1],        label='KalmanNet', alpha=0.85)\n",
        "if 'pf_path' in DATA:\n",
        "    plt.plot(DATA['pf_path'][:,0], DATA['pf_path'][:,1], label='Particle Filter', alpha=0.6)\n",
        "plt.xlabel('x [m]'); plt.ylabel('y [m]'); plt.axis('equal')\n",
        "plt.title('2-D path — Tracker vs KF vs KalmanNet')\n",
        "plt.legend(); plt.tight_layout(); plt.show()\n",
        "\n",
        "# ---- ACCELERATION COMPARISON (derived vs real) --------------------------------\n",
        "dt     = DATA['dt']\n",
        "vel_kn = np.gradient(knet_path, dt, axis=0)\n",
        "acc_kn = np.gradient(vel_kn, dt, axis=0)[1:-1]\n",
        "acc_rl = DATA['acc_lpf_trimmed'][1:-1]        # synced real accel\n",
        "ts     = np.arange(len(acc_kn))\n",
        "\n",
        "fig,axs = plt.subplots(2,1,figsize=(9,6),sharex=True)\n",
        "axs[0].plot(ts, acc_rl[:,0], label='Acc_x real')\n",
        "axs[0].plot(ts, acc_kn[:,0], label='Acc_x KalmanNet', alpha=0.7)\n",
        "axs[0].set_ylabel('Acc_x'); axs[0].grid(); axs[0].legend()\n",
        "\n",
        "axs[1].plot(ts, acc_rl[:,1], label='Acc_y real')\n",
        "axs[1].plot(ts, acc_kn[:,1], label='Acc_y KalmanNet', alpha=0.7)\n",
        "axs[1].set_ylabel('Acc_y'); axs[1].set_xlabel('Time step'); axs[1].grid(); axs[1].legend()\n",
        "\n",
        "fig.suptitle('Acceleration: KalmanNet-derived vs Real Accelerometer')\n",
        "plt.tight_layout(); plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW_ma5sPdPD1"
      },
      "source": [
        "comparison tables and graph"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
